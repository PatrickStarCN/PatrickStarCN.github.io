<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[生成方法与判定方法]]></title>
    <url>%2F2018%2F04%2F25%2FGenApp-and-DisApp%2F</url>
    <content type="text"><![CDATA[监督学习方法分生成方法与判定方法，这篇文章是关于二者理解的笔记。 李航老师的《《统计学习方法》P18:生成方法由数据学习联合概率分布$P(X,Y)$,然后再求条件概率分布作为预测模型。典型的生成模型有：朴素贝叶斯，隐马尔科夫模型。判别方法有数据直接学习决策函数$f(X)$或者条件概率分布$P(XY)$作为预测模型。典型的判定模型有：KNN，决策树，LR，SVM等。 生成方法的特点：生成方法可以还原联合概率分布，而判别方法则不能；生成方法的学习收敛速度更快，即当样本容量增加的时候，学习的模型可以更快的收敛于真实的模型；当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能用。 判别方法的特点：判别方法直接学习的是条件概率或者决策函数，直接面对预测，往往学习的准确率更高；由于直接学习或者，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。 生成方法对于历史数据有多少个类别就要生成多少个模型，然后用新数据特征去匹配这些模型，取最符合的。 判别方法根据历史数据直接生成一个判别式，新数据进来直接就可以判断他属于哪一个类别。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>笔记</tag>
        <tag>概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数学基础之极大似然估计（MLE）]]></title>
    <url>%2F2018%2F04%2F25%2FMLE%2F</url>
    <content type="text"><![CDATA[“概率论只不过是把常识用数学公式表达了出来” —拉普拉斯 极大似然估计是机器学习算法常用的的一种参数估计方法，这篇文章是MLE和相关概念的笔记。 一些概念：先验概率，事情还没有发生，要求这件事情发生的可能性的大小，是根据以往经验和分析得到的概率。后验概率，事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小。条件概率， 贝叶斯公式条件概率公式：$$P(A|B)=\frac{P(AB)}{P(B)}$$贝叶斯公式可以由条件概率公式推到出来：$$P(A_i|B)=\frac{P(A_iB)}{P(B)}=\frac{P(B|A_i)P(A_i)}{P(B)}$$贝叶斯公式中各部分含义： $P(A_i)$,$A_i$的先验概率 $P(B)$,$B$的先验概率 $P(A_i|B)$, 直观上理解，贝叶斯公式描述的是在$B$发生的情况下，$A_i$的概率 极大似然估计（MLE）]]></content>
      <categories>
        <category>数学基础</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>笔记</tag>
        <tag>数学</tag>
        <tag>概率学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记之LR(逻辑回归)]]></title>
    <url>%2F2018%2F04%2F25%2FNoteLR%2F</url>
    <content type="text"><![CDATA[逻辑回归是一个回归函数，但是应用在分类问题上，可以对事件发生的概率进行预测。 线性回归线性回归公式：$$f(x_i)=\omega x_i+b$$目的是使$f(x_i)$尽可能的靠近$y_i$(实际值). 求解$\omega$和$b$一般采均方误差最小化，这种方法又被称为“最小二乘法”，即找到一条直线使所有点到直线的欧氏距离最小，即 $$(\omega^,b^) = \mathop{\arg\min}\limits_{(\omega,b)}\sum_{i=1}^m{(f(x_i)-u_i)^2}= \mathop{\arg\min}\limits_{(\omega,b)}\sum_{i=1}^m{(y_i-\omega x_i-b)^2}$$ 求解$\omega$和$b$，将上式分别对$\omega$和$b$求导有： $$\omega =\frac{\sum\limits_{i=1}^m{y_i(x_i-\bar x)}}{\sum\limits_{i=1}^m{x_i^2-\frac1m\bigg(\sum\limits_{i=1}^m{x_i}\bigg)^2}}$$$$b=\frac1m\sum_{i=1}^m(y_i-\omega x_i)$$ 上述是一元线性回归的情况.对于多元线性回归则有： $$f(\boldsymbol x_i)=\boldsymbol \omega^ \mathrm{T}\boldsymbol x_i+b$$使$f(\boldsymbol x_i)$尽可能的靠近$y_i$(实际值)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>笔记</tag>
        <tag>算法</tag>
        <tag>LR</tag>
        <tag>逻辑回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习笔记之SVM(支持向量机)]]></title>
    <url>%2F2018%2F04%2F25%2FNoteSVM%2F</url>
    <content type="text"><![CDATA[支持向量机是一种二分类模型，是特征空间上间隔最大化的线性分类器。这篇是关于SVM的笔记。 Todo list： 算法原理 算法推倒 算法优化 算法实现 一些疑问]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>笔记</tag>
        <tag>算法</tag>
        <tag>SVM</tag>
        <tag>支持向量机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习性能评估指标]]></title>
    <url>%2F2018%2F04%2F23%2FThePerformanceEvaluationOfMachineLearning%2F</url>
    <content type="text"><![CDATA[机器学习在不同的业务需求下，需要使用不同的评估指标对算法效果进行评估，这篇文章将对常见的评估指标进行总结。 Todo list： 分类任务 Accuracy Precision Recall F1 Score Roc curve PR curve AUC 回归任务 MAE MSE 由于翻译问题，Accuracy（准确率），Precision(精确率，查准率)，Recall（召回率，查全率）中文表述会存在歧义，因此下文均用英文表述。 评估指标根据任务类型不同主要分为两类： 分类任务评估指标 Accuracy Precision Recall F1 Score Roc curve PR curve AUC 回归任务评价指标 MAE (Mean Absolute Error，绝对平均误差) MSE (Mean Squared Error，均方误差) 混淆矩阵提到评价方法首先我们先引入混淆矩阵（Confusion Matrix)的概念，因为接下来的分类任务的评价指标Accuracy，precision，recall，F1 score都可以用混淆举中的元素表示。 混淆矩阵是用来反映某一个分类模型的分类结果的，其中行代表的是真实的类，列代表的是模型的分类，如下表： 分类任务评价指标AccuracyAccuracy是评价指标里最易懂，最直观的一个。它的定义如下: $$ Accuracy= \frac{分类正确的样本数}{总样本数} $$ 用混淆矩阵表示就是：$$ Accuracy= \frac{TP+TN}{TP+TN+FP+FN} $$ 即Accuracy表示分类器正确分类的样本数与总样本数之比。 注意不均衡数据会对Accuracy产生极大影响。例如在做债务人逾期率预测任务时，逾期（即未在指定日期还款）的概率相对较低，在此我们假设100人里有一人逾期，如果分类器简单的把所有人都标记为非逾期（未进行预测），那么这个任务的Accuray将会是99%，99%的准确率看起来很高，然而并未反应分类器的好坏（分类器只是简单地标记所有样本为非逾期）。 Precision 和 Recall先从混淆矩阵定义来看Precision和Recall的定义：$$ Presion= \frac{TP}{TP+FP} $$$$ Recall= \frac{TP}{TP+FN} $$TP表示预测为正例中真正的正样本数，TP+FP表示预测为正的所有样本数，所以Precision表示的是预测为正例的样本中有多少是真正的正例。 同理TP+FN表示样本中正例的总数，所以Recall表示的是样本中的正例被准确预测的比例。 Precision和Recall有着自己的侧重点，在不同的业务需求下重要性也不同。下面举例说明： 推荐算法中，往往会给用户推荐较多的候补项，这时候我们希望我们推荐的候补项中尽可能多的是用户感兴趣的内容，这种情况我们希望Precision尽可能的大。 地震预测任务中，我们宁愿误报也不愿意错过一次可能的正确预测，所以我们的侧重点就是尽可能的提高样本中的正例被准确预测的比例，如果100次任务里只有一次地震，我们要提高这次地震被预测出来的概率，也就是“宁可错杀以前也不愿放走一个”，这种情况就希望Recall尽可能的大。 F1 ScoreF1 Score是一个综合考虑Precision和Recall的评价指标，他的定义是二者的调和平均：$$F1=\frac{1}{\frac{1}{2}(\frac{1}{Precision}+\frac{1}{Recall})}\implies F1=\frac{2\cdot Precision\cdot Recall}{Precision+Recall}$$Precision和Recall都高时F1 Score也会高。 F1 Score的变种$F_\beta=（1+\beta^2）\cdot\frac{Precision \cdot Recall}{\beta^2 \cdot Precision+Recall}$运行我们通过调节$\beta$值来调整Precision和Recall的权重。其中$\beta&gt;0$,当$\beta&gt;1$时Precision有更大影响，$\beta&lt;1$时Recall有更大影响，$\beta=1$时就是标准的F1。 PR Curve###]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>笔记</tag>
        <tag>评估方法</tag>
      </tags>
  </entry>
</search>
